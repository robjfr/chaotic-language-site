---
title: "Grammar: formally incomplete or just random?"
date: 2008-04-21
draft: false
tags: ['linguistics', 'randomness', 'compression']
categories: ["articles"]
summary: "Discussion of whether natural language grammar is formally incomplete or simply random, referencing Shannon's entropy estimates."
---

Natural language appears to be random (c.f. from the Hutter Prize page):

"...in 1950, Claude Shannon estimated the entropy (compression limit)
of written English to be about 1 bit per character [3]. To date, no
compression program has achieved this level."
(http://cs.fit.edu/~mmahoney/compression/rationale.html)

The most successful contemporary natural language technologies are probabilistic.

The usual explanation is that something external selects between alternatives which are equally probable on linguistic grounds. Commonly this external factor is assumed to be "meaning".

Noam Chomsky in the 1950's convinced a generation this external factor was an innate "language organ".

We now know that incomplete formal systems show properties of randomness.